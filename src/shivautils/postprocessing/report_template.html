<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Report</title>
</head>

<body>
    <h1>Results report {{ data_origin }}</h1>
    {% if shiva_logo %}
    <img src='data:image/png;base64, {{ shiva_logo }}' width="100" height="100">
    {% endif %}

    {% for pred in pred_stat_dict %}
    <div class="table"></div>
    <h2> {{ pred_stat_dict[pred]['title'] }}</h2>
    {{pred_stat_dict[pred]['metrics_table'] | safe}}
    <p>Brain volume: {{ pred_stat_dict[pred]['brain_volume'] }} mm<sup>3</sup></p>
    <p>Cluster threshold: {{ pred_stat_dict[pred]['cluster_threshold'] }}</p>
    <p>Cluster size filter: {{ pred_stat_dict[pred]['cluster_min_vol'] }}</p>
    <object type='image/svg+xml' data='data:image/svg+xml;base64, {{ pred_stat_dict[pred]["census_figure"] }}'
        width="600" height="400"></object>
    </div>
    {% endfor %}

    {% if ((bounding_crop is not none) or (overlayed_brainmask_1 is not none)
    or (isocontour_slides_FLAIR_T1 is not none) or (overlayed_brainmask_2 is not none)) %}
    <div class="test">
        <h1>Quality control</h1>
        {% if bounding_crop %}
        <h2>Crop-box and first brain mask</h2>
        <p>Display of the cropping region used on the conformed image (256x256x256 at 1.0 mm<sup>3</sup>
            resolution), as well as the first brain mask used to position the crop-box. The cropped
            conformed image is what is fed to the deep-learning model.</p>

        <object type='image/svg+xml' data='data:image/svg+xml;base64, {{ bounding_crop }}' width="600"
            height="400"></object>
        {% endif %}
        {% if overlayed_brainmask_1 %}
        <h2>Overlay of final brainmask over cropped {{ modality }}</h2>
        <p>Overlay of the brainmask on {{ modality }} image: {{ image_size }} voxels at {{ resolution }} mm<sup>3</sup>,
            (with censoring for voxels outside the brain mask)</p>
        <img src='data:image/png;base64, {{ overlayed_brainmask_1 }}' width="600" height="300">
        {% endif %}

        {% if isocontour_slides_FLAIR_T1 %}
        <h2>Isocontour Slides for coregistration FLAIR on T1w</h2>
        <p>Isocontour of the FLAIR image coregister on T1w image that enters the classifier: {{ resolution }}
            mm<sup>3</sup> with {{ image_size }}, (within brain mask and with censoring for voxels outside the brain
            mask)</p>
        <img src='data:image/png;base64, {{ isocontour_slides_FLAIR_T1 }}' width="600" height="300">
        {% endif %}

        {% if overlayed_brainmask_2 %}
        <h2>Overlay of final brainmask over cropped SWI</h2>
        <p>Overlay of the brainmask on SWI image: {{ image_size }} voxels at {{ resolution }} mm<sup>3</sup>,
            (with censoring for voxels outside the brain mask)</p>
        <img src='data:image/png;base64, {{ overlayed_brainmask_2 }}' width="600" height="300">
        {% endif %}
    </div>
    {% endif %}

    <h2>Additional workflow informations and parameters</h2>
    <p>Shiva version: {{ version }}</p>
    <p>Input parameters:<br>
        - "percentile" (as upper threshold during intensity normalisation): {{ percentile }}<br>
        - "threshold" (to binarise estimated brain masks): {{ threshold }}<br>
        - "final_dimensions" (image dimensions output by the AI model): {{ image_size }}<br>
        - "voxels_size" (resampling resolution, used by the AI model): {{ resolution }} mm<sup>3</p>
    <p>Unique identifers (md5) for the AI models:</p>
    {% for pred, file_dict in models_uid.items() %}
    <p>{{pred}} model files:<br>
        {% for filename, md5 in file_dict.items() %}
        - {{filename}}: {{md5}}<br>
        {% endfor %}
    </p>
    {% endfor %}
    {% if wf_graph %}
    <h2>Processing workflow diagram</h2>
    <object type='image/svg+xml' data='data:image/svg+xml;base64, {{ wf_graph }}' width="700" height="500"></object>
    {% endif %}
</body>

</html>